{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2                                          #Importando as bibliotecas necessárias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabor_filter(img, angle):\n",
    "    \n",
    "    '''\n",
    "    Função que aplica o gabor filter em uma determinada direção 'angle'.\n",
    "    \n",
    "    Como o objetivo é detecção de estruturas e não textura, a imagem é convertida em binária, com um treshold de 180,\n",
    "    visto que a qualidade da imagem é alta e este valor separa bem o background da letra.\n",
    "    \n",
    "    A ideia em aplicar o gabor é isolar estruturas em determinas direções, dessa forma conseguimos analisar as diferenças\n",
    "    entre as assinaturas em cada direção, o que confere uma maior robustez a análise.\n",
    "    \n",
    "    Foram escolhidas as 4 direções tradicionais: horizontal(pi), vertical(pi/2), \n",
    "    diagonal positiva(pi/4) e diagonal negativa (-pi/4)\n",
    "    '''\n",
    "    \n",
    "    #contruindo o filtro com uma máscara 20x20\n",
    "    g_kernel = cv2.getGaborKernel((20, 20), 8.0, angle, 10.0, 0.5, 0, ktype=cv2.CV_32F) \n",
    "    \n",
    "    ret, img = cv2.threshold(img,180,255,cv2.THRESH_BINARY) #convertendo a imagem em binária\n",
    "    filtered_img = cv2.filter2D(img, cv2.CV_8UC3, g_kernel) #Aplicando o filtro\n",
    "    \n",
    "    return filtered_img #retorna a imagem filtrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convex_hull(img):\n",
    "    \n",
    "    '''\n",
    "    Função que detecta os contornos da imagem através da função 'findContours' e aplica o convex hull.\n",
    "    \n",
    "    A ideia por trás do algoritmo é detectar estrutuas e extrair atributos das mesmas, supostamente assinaturas diferentes\n",
    "    terão estruturas diferentes e seus atributos serão usados como a base da classificação.\n",
    "    \n",
    "    A função findContours detecta os contornos da imagem, tais contornos são usados pelo convex hull para gerar poligonos\n",
    "    em volta deles, então são extraidos atributos destes poligonos. \n",
    "    \n",
    "    Como pretendemos classificar a imagem e não os polígonos, é feita então uma média para cada atributo\n",
    "    de todos os poligonos detectados.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    blur = cv2.blur(img, (3, 3)) #Gerando um blur na imagem (recomendado pelo algoritmo)\n",
    "    ret, thresh = cv2.threshold(blur, 180, 255, cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #achando os contornos\n",
    "    \n",
    "    hulls = []\n",
    "    val_vector = []\n",
    "\n",
    "    # Encontrando os poligonos para cada contorno encontrado\n",
    "    for i in range(len(contours)):\n",
    "        #Armazenando em um vetor de resultado\n",
    "        hulls.append(cv2.convexHull(contours[i], False))\n",
    "        \n",
    "    drawing = np.zeros((thresh.shape[0], thresh.shape[1], 3), np.uint8)\n",
    "        \n",
    "    for i in range(len(contours)):\n",
    "        color_contours = (0, 255, 0) # green - color for contours\n",
    "        color = (255, 0, 0) # blue - color for convex hull\n",
    "        # draw ith contour\n",
    "        cv2.drawContours(drawing, contours, i, color_contours, 1, 8, hierarchy)\n",
    "        # draw ith convex hull object\n",
    "        if(cv2.contourArea(hulls[i])>200):\n",
    "            cv2.drawContours(drawing, hulls, i, color, 1, 8)\n",
    "\n",
    "    \n",
    "    return hulls #retorna os poligonos encontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(hulls):\n",
    "    \n",
    "    '''\n",
    "    Função que extrai os atributos dos poligonos encontrados, sendo eles:\n",
    "    \n",
    "    cx: Corresponde a coordenada x do centroid do poligono\n",
    "    cy_vector: Corresponde a coordenada x do centroid do poligono\n",
    "    area: Area total do poligono\n",
    "    perimeter: Perimetro total do poligono\n",
    "    total_hull: Quantidade total de poligonos detectados\n",
    "    \n",
    "    Como são detectados diversos poligonos, muitos deles de tamanho bastante reduzido, foi definido um threshold\n",
    "    e só serão analisados polígonos com área superior a 200\n",
    "    \n",
    "    além dos atributos, nessa função é incluida também a classe da imagem: G, F ou D\n",
    "    '''\n",
    "    \n",
    "    #vetores que armazenam os valores de cada poligono\n",
    "    cx_vector = []\n",
    "    cy_vector = []\n",
    "    area_vector =[]\n",
    "    perim_vector = []\n",
    "    total_hull = 0\n",
    "    \n",
    "    #Analisando cada poligono detectado\n",
    "    for k in range(1,len(hulls)):  #O primeiro é ignorado pois corresponde ao contorno da imagem toda\n",
    "    \n",
    "        if(cv2.contourArea(hulls[k])>200): #Filtrando os poligonos pela área\n",
    "            \n",
    "            M = cv2.moments(hulls[k])          #determinando o momento para calcular os centrois\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "            \n",
    "            cx_vector.append(cx)\n",
    "            cy_vector.append(cy) \n",
    "            area_vector.append(cv2.contourArea(hulls[k]))       #calculando os atributos\n",
    "            perim_vector.append(cv2.arcLength(hulls[k],True))\n",
    "            total_hull += 1\n",
    "    \n",
    "    # Calculando as médias e atribuindo ao vetor de retorno  \n",
    "    val_vector = [float('%.4f' % statistics.mean(cx_vector)),\n",
    "                  float('%.4f' % statistics.mean(cy_vector)),\n",
    "                  float('%.4f' % statistics.mean(area_vector)),\n",
    "                  float('%.4f' % statistics.mean(perim_vector)), \n",
    "                  total_hull]\n",
    "   \n",
    "  \n",
    "    return val_vector #retornando os valores dos atributos extraidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_writer(val_vector, output_path):\n",
    "    \n",
    "    '''\n",
    "    Função que armazena os atributos em um .csv\n",
    "    Caso o arquivo não exista, o mesmo é criado e incluido um cabeçalho com o nome dos atributos    \n",
    "    '''\n",
    "    \n",
    "    path = output_path\n",
    "    key_vector = ['cx_img','cy_img','area_img','perim_img','hulls_img','cx_g1','cy_g1','area_g1','perim_g1','hulls_g1',\n",
    "                  'cx_g2','cy_g2','area_g2','perim_g2','hulls_g2', 'cx_g3','cy_g3','area_g3','perim_g3','hulls_g3',\n",
    "                  'cx_g4','cy_g4','area_g4','perim_g4','hulls_g4', 'class']\n",
    "        \n",
    "    if not os.path.exists(path):\n",
    "        with open(path, 'w+') as f:\n",
    "            for i in range(len(key_vector)):\n",
    "                aux_escrita = str(i)+'_'+str(key_vector[i])\n",
    "                f.write(str(aux_escrita))\n",
    "                if i == len(key_vector)-1:\n",
    "                    #f.write('\\t')\n",
    "                    #f.write('Class')\n",
    "                    f.write('\\n')\n",
    "                else:\n",
    "                    f.write('\\t')\n",
    "            for i in range(len(val_vector)):\n",
    "                f.write(str(val_vector[i]))\n",
    "                if i == len(val_vector)-1:\n",
    "                    f.write('\\n')\n",
    "                else:\n",
    "                    f.write('\\t')\n",
    "    else:\n",
    "        with open(path, 'a') as f:\n",
    "            for i in range(len(val_vector)):\n",
    "                f.write(str(val_vector[i]))\n",
    "                if i == len(val_vector)-1:\n",
    "                    f.write('\\n')\n",
    "                else:\n",
    "                    f.write('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_extraction(input_path, output_path):\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Por fim são extraidos mesmos atribuitos de uma mesma imagem em 5 situações:\n",
    "    \n",
    "        1) Da imagem original\n",
    "        2) De cada imagem passada pelo gabor filter em cada uma das 4 direções\n",
    "        \n",
    "        \n",
    "    A princpio haveria o grupo de treino/teste e um outro de validação, porém o grupo de validação só será utilizado\n",
    "    pelos avaliadores. Então tomei a liberdade de alterar um pouco a estrutura dos dados que me foram enviados.\n",
    "    \n",
    "    Deixei como estavam os grupos Disguised e Simulated (Forged)\n",
    "    Porém uni os grupos de Reference e Genuine como sendo ambos Genuine\n",
    "    \n",
    "    Sendo assim, optei por uma classificação multi-class entre Genuine, Forged e Disguised utilizando todas as imagens\n",
    "    como treino/teste, fazendo um cross-validation e tendo como parametro de avaliação a acurácia.\n",
    "    '''\n",
    "    begin = time.time()\n",
    "    \n",
    "    folders = os.listdir(input_path)\n",
    "    \n",
    "    for fd in folders:\n",
    "        \n",
    "        files = os.listdir(input_path+'\\\\'+fd)\n",
    "        \n",
    "        if(fd == 'Genuine' or fd == 'Reference'):\n",
    "            img_class = 'G'\n",
    "        elif(fd == 'Simulated'):\n",
    "            img_class = 'F'\n",
    "        elif(fd == 'Disguise'):\n",
    "            img_class = 'D'\n",
    "        else:\n",
    "            print('Unavailable image folder')\n",
    "           \n",
    "        for fl in files:\n",
    "    \n",
    "            output_path = output_path\n",
    "            original_img = cv2.imread(input_path+'\\\\'+fd+'\\\\'+fl)\n",
    "            gray = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY) # convertendo para niveis de cinza\n",
    "\n",
    "            gabor_1 = gabor_filter(gray, np.pi)\n",
    "            gabor_2 = gabor_filter(gray, np.pi/2)\n",
    "            gabor_3 = gabor_filter(gray, np.pi/4)          #Aplicando o gabor filter em cada direção\n",
    "            gabor_4 = gabor_filter(gray, (np.pi/4)*-1)\n",
    "\n",
    "            original_img_features = features_extractor(convex_hull(gray))\n",
    "            gabor_1_features = features_extractor(convex_hull(gabor_1))\n",
    "            gabor_2_features = features_extractor(convex_hull(gabor_2))    #Extraindo os atributos de cada uma das 5 imagens\n",
    "            gabor_3_features = features_extractor(convex_hull(gabor_3))\n",
    "            gabor_4_features = features_extractor(convex_hull(gabor_4))\n",
    "\n",
    "            features = original_img_features+gabor_1_features+gabor_2_features+gabor_3_features+gabor_4_features+[img_class]\n",
    "            csv_writer(features, output_path)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"Extraction complete in \", end-begin, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete in  346.057510137558  seconds\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    \n",
    "    #caminho onde estão as pastas com as imagens\n",
    "    roth_input_path = r'C:\\Users\\Administrator\\Desktop\\Final 2\\02-FraudDetection\\TrainingSet'\n",
    "    #caminho onde o csv de atributos será salvo\n",
    "    output_path = r'C:\\Users\\Administrator\\Desktop\\Final 2\\features.csv'\n",
    "    \n",
    "    run_extraction(roth_input_path, output_path)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
